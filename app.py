import streamlit as st
import requests
import json
import uuid
import time
import pytesseract
from PIL import Image
import base64
from io import BytesIO

# --- ‚úÖ Correct Tesseract path (Windows) ---
pytesseract.pytesseract.tesseract_cmd = r"C:\\Program Files\\Tesseract-OCR\\tesseract.exe"

# --- Page Config ---
st.set_page_config(page_title="üí¨ ChatGPT Clone", page_icon="üí¨", layout="wide")
st.title("üí¨ Chat with Ollama")

# --- Initialize session state ---
if "conversations" not in st.session_state:
    st.session_state["conversations"] = {}
if "current_chat" not in st.session_state:
    chat_id = str(uuid.uuid4())
    st.session_state["current_chat"] = chat_id
    st.session_state["conversations"][chat_id] = {"title": "New Chat", "messages": []}
if "pinned_chats" not in st.session_state:
    st.session_state["pinned_chats"] = set()
if "action_prompt" not in st.session_state:
    st.session_state["action_prompt"] = None
if "pending_prompt" not in st.session_state:
    st.session_state["pending_prompt"] = None
if "show_uploader" not in st.session_state:
    st.session_state["show_uploader"] = False

# --- Sidebar ---
with st.sidebar:
    st.markdown("### ‚öôÔ∏è Settings")
    model = st.selectbox("Choose a model", ["phi3", "mistral", "llama2"])

    if st.button("‚ûï New Chat"):
        chat_id = str(uuid.uuid4())
        st.session_state["current_chat"] = chat_id
        st.session_state["conversations"][chat_id] = {"title": "New Chat", "messages": []}

    st.markdown("### üìú Chat History")
    for chat_id, chat_data in st.session_state["conversations"].items():
        title = chat_data["title"]
        if st.button(title, key=chat_id):
            st.session_state["current_chat"] = chat_id

    st.markdown("### ‚≠ê Pinned Chats")
    for chat_id in st.session_state["pinned_chats"]:
        title = st.session_state["conversations"][chat_id]["title"]
        if st.button(f"‚≠ê {title}", key=f"pinned_{chat_id}"):
            st.session_state["current_chat"] = chat_id

    is_pinned = st.session_state["current_chat"] in st.session_state["pinned_chats"]
    pin_label = "Unpin Current Chat" if is_pinned else "‚≠ê Pin Current Chat"
    if st.button(pin_label):
        if is_pinned:
            st.session_state["pinned_chats"].remove(st.session_state["current_chat"])
        else:
            st.session_state["pinned_chats"].add(st.session_state["current_chat"])

    if st.button("üóëÔ∏è Clear Current Chat"):
        st.session_state["conversations"][st.session_state["current_chat"]]["messages"] = []

    st.markdown("<div class='footer'>üöÄ Powered by Ollama + Streamlit</div>", unsafe_allow_html=True)

# --- üåô ChatGPT-like Modern UI ---
st.markdown(
    """
    <style>
    @import url('https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600&display=swap');
    .stApp {background-color:#131416;color:#e6e6e6;font-family:'Inter',sans-serif;}
    section[data-testid="stSidebar"]{background-color:#1f2023 !important;color:#f1f5f9 !important;}
    h1{text-align:center;font-weight:700;background:linear-gradient(90deg,#10a37f,#4f46e5);
        -webkit-background-clip:text;-webkit-text-fill-color:transparent;padding:0.3rem 0;font-size:2rem!important;}
    .chat-container{max-width:850px;margin:0 auto;height:calc(100vh - 200px);overflow-y:auto;
        padding:1.5rem;display:flex;flex-direction:column;scroll-behavior:smooth;}
    .chat-container::-webkit-scrollbar{width:6px;}
    .chat-container::-webkit-scrollbar-thumb{background:#3a3b41;border-radius:6px;}
    .chat-bubble{border-radius:12px;padding:1rem 1.4rem;margin:0.7rem 0;max-width:80%;
        word-break:break-word;font-size:1rem;line-height:1.6;animation:fadeIn 0.25s ease-in-out;
        box-shadow:0 1px 3px rgba(0,0,0,0.3);}
    @keyframes fadeIn{from{opacity:0;transform:translateY(10px);}to{opacity:1;transform:translateY(0);} }
    .chat-bubble.user{background-color:#0a84ff;color:white;align-self:flex-end;text-align:right;
        border-bottom-right-radius:4px;}
    .chat-bubble.assistant{background-color:#2a2b32;color:#e5e7eb;align-self:flex-start;
        border-bottom-left-radius:4px;}
    .chat-bubble.document{background-color:#3b3b46;color:#e5e7eb;align-self:flex-start;
        border-left:4px solid #10a37f;}
    .bottom-input{position:fixed;bottom:0;left:260px;right:0;background:#131416;padding:1rem 2rem;
        border-top:1px solid #2a2b32;z-index:999;}
    @media (max-width:768px){.bottom-input{left:0;padding:1rem;}}
    div[data-baseweb="input"] input{background-color:#2a2b32!important;color:#e5e7eb!important;
        border:none!important;border-radius:8px!important;font-size:1rem!important;}
    .footer{text-align:center;font-size:0.85rem;color:#a1a1aa;margin-top:2rem;}
    .typing-cursor::after{content:'‚ñå';animation:blink 1s infinite;}
    @keyframes blink{0%,100%{opacity:1;}50%{opacity:0;}}
    </style>

    <!-- ‚úÖ Auto-scroll script -->
    <script>
        var chatDiv = window.parent.document.querySelector('.chat-container');
        if (chatDiv) {
            chatDiv.scrollTop = chatDiv.scrollHeight;
        }
    </script>
    """,
    unsafe_allow_html=True
)

# --- Current chat ---
current_chat_id = st.session_state["current_chat"]
current_chat = st.session_state["conversations"][current_chat_id]

# --- Chat Display ---
st.markdown("<div class='chat-container'>", unsafe_allow_html=True)
for i, msg in enumerate(current_chat["messages"]):
    bubble_class = f"chat-bubble {msg['role']}"
    st.markdown(f"<div class='{bubble_class}'>{msg['content']}</div>", unsafe_allow_html=True)

    if msg["role"] in ["assistant", "document"] and i == len(current_chat["messages"]) - 1:
        cols = st.columns(3)
        if cols[0].button("üîç Explain More"):
            st.session_state["pending_prompt"] = f"Explain this in detail:\n\n{msg['content']}"
        if cols[1].button("üìù Summarize"):
            st.session_state["pending_prompt"] = f"Summarize this:\n\n{msg['content']}"
        if cols[2].button("üåê Translate"):
            st.session_state["pending_prompt"] = f"Translate this into Hindi:\n\n{msg['content']}"
st.markdown("</div>", unsafe_allow_html=True)

# --- Bottom Input ---
st.markdown("<div class='bottom-input'>", unsafe_allow_html=True)
cols = st.columns([9, 1])
prompt_input = cols[0].chat_input("Message ChatGPT...")
if cols[1].button("‚ûï"):
    st.session_state["show_uploader"] = not st.session_state.get("show_uploader", False)
st.markdown("</div>", unsafe_allow_html=True)

# --- ‚úÖ OCR Upload Section (Fixed Image Display) ---
if st.session_state.get("show_uploader"):
    uploaded_image = st.file_uploader("üì§ Upload image for OCR", type=["png", "jpg", "jpeg"])
    if uploaded_image:
        image = Image.open(uploaded_image)

        # Convert image to base64 string
        buffered = BytesIO()
        image.save(buffered, format="PNG")
        img_str = base64.b64encode(buffered.getvalue()).decode()
        img_html = f"<img src='data:image/png;base64,{img_str}' width='200'>"

        try:
            extracted_text = pytesseract.image_to_string(image).strip()
            chat_content = f"üñºÔ∏è {img_html}<br>"
            if extracted_text:
                chat_content += f"üßæ **Extracted Text:**<br>{extracted_text}"

            current_chat["messages"].append({
                "role": "document",
                "content": chat_content
            })

            st.session_state["show_uploader"] = False
            st.rerun()
        except Exception as e:
            st.error(f"‚ùå OCR Error: {e}")

# --- Determine prompt ---
prompt = None
if st.session_state.get("pending_prompt"):
    prompt = st.session_state.pop("pending_prompt")
elif st.session_state.get("action_prompt"):
    prompt = st.session_state.pop("action_prompt")
elif prompt_input:
    prompt = prompt_input

# --- Send prompt to Ollama with Typewriter + Auto-scroll ---
if prompt:
    if current_chat["title"] == "New Chat":
        current_chat["title"] = prompt[:30] + ("..." if len(prompt) > 30 else "")
    current_chat["messages"].append({"role": "user", "content": prompt})
    st.markdown(f"<div class='chat-bubble user'>{prompt}</div>", unsafe_allow_html=True)

    placeholder = st.empty()
    placeholder.markdown("<div class='chat-bubble assistant typing-cursor'>ü§ñ Thinking...</div>", unsafe_allow_html=True)

    full_reply = ""
    start_time = time.time()
    try:
        response = requests.post(
            "http://localhost:11434/api/chat",
            json={"model": model, "messages": current_chat["messages"], "stream": True},
            stream=True,
            timeout=120
        )
        text_placeholder = st.empty()
        for line in response.iter_lines():
            if line:
                data = json.loads(line.decode("utf-8"))
                token = data.get("message", {}).get("content", "")
                if token:
                    full_reply += token
                    text_placeholder.markdown(
                        f"<div class='chat-bubble assistant typing-cursor'>{full_reply}</div>",
                        unsafe_allow_html=True
                    )
                    st.markdown(
                        "<script>var chatDiv = window.parent.document.querySelector('.chat-container');"
                        "if(chatDiv){chatDiv.scrollTop = chatDiv.scrollHeight;}</script>",
                        unsafe_allow_html=True
                    )
                    time.sleep(0.02)
        elapsed = time.time() - start_time
        text_placeholder.markdown(
            f"<div class='chat-bubble assistant'>{full_reply}"
            f"<br><span style='color:#a1a1aa;font-size:0.8rem;'>‚è±Ô∏è {elapsed:.2f}s</span></div>",
            unsafe_allow_html=True
        )
        current_chat["messages"].append({"role": "assistant", "content": full_reply})
    except requests.exceptions.ConnectionError:
        st.error("‚ùå Couldn't connect to Ollama. Make sure Ollama is running on localhost:11434.")
    except Exception as e:
        st.error(f"‚ùå Error: {e}")
